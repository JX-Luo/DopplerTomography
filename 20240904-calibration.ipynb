{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e876b0fc-9285-44c6-bf84-87d5fd4311ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d42c3-069c-41e6-81be-c9ba13e527c0",
   "metadata": {},
   "source": [
    "# Things to calibrate before calibration\n",
    "  Upon opening up the spectrometer, seeing the psuedocolor image, the first question is: <b>what does it mean by the color...?</b>   \n",
    "  The important thing is that the color is just an indicator of the pixel value!!!! It is just an indicator, for you to see the <b>contraction</b>, and the color itself means nothing else than contraction without the <b>colorbar</b>. Remember the important lesson of how to choose a colormap? That is the point!!   \n",
    "  <b>But</b> what you want is <b>physical information!!</b> The color itself is meaningless, you have to have an insight.   \n",
    "  So what does it mean by the color after all? It is just an indicator of the pixel value, which is again proportional to the <b>total amount of light</b> that comes into our camera!!! which include the <b>desirable signal</b> and the <b>noise</b>!!!     \n",
    "\n",
    "  So here is the lesson, that is if you didn't see anything on the camera except the noise, it doesn't necessarily mean that there is no signal, but it may simply mean that the noise buried out the signal!!!\n",
    "\n",
    "  Remember our system took a long tunnel with two lenses on that before the light reaches the camera. The tunnel is an important source of noise. So we have to use black paper and plastic plate to block out the light. Be careful!!! This is extremely important to your <b>signal to noise ratio _SNR_</b>. This matters on your experimental result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d7d0b-7fc2-4fca-9d4a-516c78223630",
   "metadata": {},
   "source": [
    "[photo]\n",
    "[photo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7012599c-50b3-402e-8217-6c5ddc2cddbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce09b2ff-15b5-49e0-b67e-e42a48c20bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e95d3f-b7dd-40ba-bc7a-f6f44d572097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7e19b5d-7928-4481-90d7-02d6aa8a8ca7",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304c141a-ad3e-4109-ad54-e7cd4e58ed1a",
   "metadata": {},
   "source": [
    "## <b>Linear Dispersion</b>\n",
    "The term linear dispersion refers to how much wavelength does a pixel corresponds, $\\frac{d\\lambda}{dx}$.   \n",
    "In linear dispersion, you obtain a curve, in which you have a linear dispersion at each wavelength. By fitting this curve, we can determine some useful parameters of the spectrometer.\n",
    "The curve is given as   \n",
    "\n",
    "$$\\left|\\frac{d\\lambda}{dx}\\right| =\\frac{1}{f}\\left( \\sqrt{\\left(\\frac{\\cos\\theta_0\\cos\\epsilon}{mg\\cdot10^{-6}}\\right)^2 - \\left(\\frac{\\lambda}{2}\\right)^2} + \\frac{m}{|m|}\\frac{\\lambda}{2}\\tan\\theta_0 \\right)$$\n",
    "\n",
    "where $\\theta_0$ is the incidental angle, $\\epsilon$ is the fan angle, $f[mm]$ is the focal length, $g$[lines(L)/mm] is the grating number, $m$ is the diffraction order. Please refer to Kado Sensei's paper.    \n",
    "高速プラズマ流と衝撃波の研究事始め２．プラズマ流計測の基礎２．３ プラズマ流の計測 ～分光法～"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc72c19-0ec6-4a43-a8ca-a1d91ef4cce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d76407f-9fa0-4b4b-9b83-9c6e59b67c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080de3cc-a4a3-4e52-b7ce-881199a7623c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40d5c17d-272a-4af5-9dd7-8809e81debd1",
   "metadata": {},
   "source": [
    "## <b>Gratign smile and instrument temperature</b>\n",
    "Grating smile is something caused by the spectrometer itself (to be specified...). The dots may not be perfectly aligned to the same horizontal pixel. The important thing is to find the exact horizontal and vertical position of each dots. Instrument temperature is how spectrometer responses to an impulse input. Ideally the light coming in should be a Derac delta, but in reality we get a gaussian. We have to find the span, full width at half maximum FWHM.    \n",
    "The strategy is to first binning toward the left, find the peaks, extract the dots, and use gaussian fitting to find the horizontal center and the standard deviation. The relation between standard deviation and FWHM can be written as \n",
    "$$\\sigma$$\n",
    "The instrument temperature and the FWHM can be written as\n",
    "$$T_i$$\n",
    "Again, please refer to Kado sensei's paper.    \n",
    "高速プラズマ流と衝撃波の研究事始め２．プラズマ流計測の基礎２．３ プラズマ流の計測 ～分光法～\n",
    "\n",
    "In TS6 experiment, we typicall measure Ar II the 480.602nm line. So, to calibrate grating smile and instrument temperature, we use Xe lamp the 479.2nm line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ff74c1-f1da-4a3e-8692-edaff1c8b233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87853fab-b1e8-4325-ba99-a12028907932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b373a86-2fc6-490a-a0fd-a9d391bc6fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d93c8d9e-ac35-40af-821b-25f04d08a97f",
   "metadata": {},
   "source": [
    "## <b>Relative intensity</b>\n",
    "Again, what we obtained in the ICCD camera is a pixel value, it is just an indicator, and it is proportional to the total amount of light coming into the camera. The total amount of light again is the radiance integrated over a certain solid angle during a certain time span. Ideally, our doppler system is designed to have the same solid angle and have the same time span, so the total amount of light is proportional to the radiance of our atoms. Remember the pixel value is proportional to the total amount of light? This means our ICCD's pixel value is propotional to the radiance of our atoms.  \n",
    "\n",
    "However unluckily, the pixel value is proportional to the radiance to <b>a different extent!!!!!</b> This should be apparent because our fiber's curvature, imperfect fiber connection and 3D printed slit all contribute to the loss of the light. We have to calibrate this.  \n",
    "\n",
    "The solution is the spherical hydrogen lamp. In which we use a certian narrow band filter to make sure the total amount of incoming light is the same. By the way, the total amount of incoming light is simply the integration of the pixel value over the wavelength. We call this value <b>relative intensity</b>. When doing experiment, divide our measured signal by this relative intensity, we get the signal that is proportional to the real radiance of atoms to the same extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb54d1-9603-4e68-9002-48f0dd2c1d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153d439-585a-4838-be13-9d15ac535aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61be0abf-23ab-467f-912b-66359925aec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a41785a-c778-4a2b-b662-ac41d295f190",
   "metadata": {},
   "source": [
    "## <b>Merging the files!!!</b>\n",
    "Okay!!! We reach here!!!  \n",
    "We finished all the chores!! Now we have to put them all into a single calibration file, and this file will be used in every experiment to produce the analyzable results.  \n",
    "The calibration file should include the x-y position in the image of each channel, its instrument temperature, relative intensity and R-Z position in TS6. Typically the R-Z and x-y position is given by the fiber array's producer. What we need to do is to keep up the remaining. As can be expected, the x-y position from the producer is always different from our measured value. But since we have some 270 channels, counting them all by hand is tedious...  \n",
    "<b>Diffucult</b> thing is how do we <b>automatiaclly</b> match them? My solution is to calculate the closest. Calculation code is given as below.  \n",
    "Finally and luckily, the pandas package is super powerful. We can simply merge our calibration file to the previous one and the work is happily done!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e55c99-eb6a-41d9-ab56-e26636da5637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf7bfc-be08-4606-9aea-8929c067ef6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9411df-44c7-4666-a83a-f7d30da65428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
